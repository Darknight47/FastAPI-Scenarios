{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2513622",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"../NLPModel/gpt2-recipes/checkpoint-750\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966281d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model from the checkpoint\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(checkpoint_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbaa7602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Required for padding (GPT-2 doesn't have one by default)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302dc4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f52de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(ingredients: list[str], max_length: int = 200) -> str:\n",
    "    prompt = \"<|startoftext|>\\nIngredients: \" + \", \".join(ingredients) + \"\\nInstructions:\\n\"\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.8,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ingredients: onion, garlic, tomato\n",
      "Instructions:\n",
      "Peel the onion from the ends and set aside. Cut into thin strips.  Add the beef broth; stir well.  Bring to a boil; reduce heat to low and simmer until beef boils.  Let cool slightly.    Remove from heat;  add salt and pepper to taste.  Gradually stir in  cornstarch.   Pour over beef; cook 1 minute or until mixture thickens. Transfer to prepared baking dish; bake  until a lightly golden brown. Cool on wire racks for 15 minutes.  Cool on wire racks for 12 minutes.   Let cool completely. Cool on wire rack for 15 minutes.   Let cool completely on wire racks for 10 minutes.   Sprinkle over flour. Gradually stir in eggs. Stir in cream and flour; beat on low speed. Gradually beat in flour until flour is stiffened. Gradually beat in egg. Gradually\n"
     ]
    }
   ],
   "source": [
    "ingredients = [\"onion\", \"garlic\", \"tomato\"]\n",
    "recipe = generate_recipe(ingredients)\n",
    "print(recipe) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
